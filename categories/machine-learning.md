# ğŸ¥‡ Machine Learning

## \[NSDI 2022\] MLaaS in the Wild: Workload Analysis and Scheduling in Large-Scale Heterogeneous GPU Clusters
ä½œè€…ï¼š

## \[ASPLOS 2023\] ElasticFlow: An Elastic Serverless Training Platform for Distributed Deep Learning
ä½œè€…ï¼šDiandian Gu, Yihao Zhao, Yinmin Zhong, Yifan Xiong, Zhenhua Han, Peng Cheng, Fan Yang, Gang Huang, Xin Jin, Xuanzhe Liuï¼ˆåŒ—å¤§å’ŒMSRï¼‰

æ–‡ç« è®¤ä¸ºç°åœ¨äº‘ä¸ŠåŸºäºæœåŠ¡å™¨çš„åˆ†é…å¹¶ä¸æ˜¯æœ€é€‚åˆDLçš„è®¾è®¡ï¼Œéœ€è¦å¼•å…¥ä¸€ä¸ªæ›´é«˜çš„æŠ½è±¡ï¼Œç”¨æˆ·æ— éœ€çŸ¥æ™“ä¸‹å±‚ç³»ç»Ÿçš„æ›´å¤šè®¾è®¡ã€‚ä½œè€…è®¤ä¸ºDLä»»åŠ¡å¯¹DDLçš„æ„ŸçŸ¥éå¸¸é‡è¦ã€‚

Key takeawaysï¼š
- æˆæœï¼šæä¾›äº†ä¸€ä¸ªServerless Trainingçš„å¹³å°ï¼Œç”¨æˆ·å¯ä»¥æ— éœ€æŒ‡å®šGPUæ•°é‡ï¼Œåªéœ€è¦æŒ‡å®šä»»åŠ¡çš„DDLå’Œè¶…å‚æ•°ï¼ˆåŒ…æ‹¬æ¨¡å‹æœ¬èº«ï¼Œæ¨¡å‹Batch Sizeï¼Œç»ˆæ­¢æ¡ä»¶ï¼Œè®­ç»ƒçš„DDLï¼Œæ•°æ®é›†ï¼Œoptimizerç­‰ç­‰ï¼‰ã€‚
- è§‚å¯Ÿï¼šä»»åŠ¡å¹¶ä¸éšç€GPUæ•°é‡çš„ä¸Šå‡è€Œååä¸Šå‡ï¼Œä¸åŒä»»åŠ¡å¯æ‰©å±•æ€§ï¼ˆGPUå˜å¤šçš„Throughputï¼‰ä¸åŒã€‚

æ–¹æ³•ï¼š
- å®šä¹‰ä½¿ç”¨çš„èµ„æºæ˜¯GPUçš„æ•°é‡å’Œè¿è¡Œæ—¶é—´çš„ä¹˜ç§¯ï¼Œå¦‚æœèƒ½å¤Ÿæ»¡è¶³ä»»åŠ¡çš„ddlæ‰åˆ†å‘ã€‚
- æ‹“æ‰‘æ„ŸçŸ¥çš„ä»»åŠ¡æ”¾ç½®æ–¹æ³•ï¼šæŠŠæ‰€æœ‰çš„GPUä»¥æ ‘çš„æ¨¡å¼ç»“åˆï¼Œåœ¨æ ‘ä¸Šæ‰¾æœ€åˆé€‚çš„èŠ‚ç‚¹ã€‚
- å‡å°‘Fragmentï¼šä½¿ç”¨Buddy Allocationï¼ŒWorkeræ•°é‡ä¸º2çš„å€æ•°ï¼Œç¡®ä¿GPUä¸å‡ºç°ç¢ç‰‡ã€‚

æ ¸å¿ƒæŒ‘æˆ˜ï¼šTrainingå¹¶ä¸Scaleï¼Œå—åˆ°Workæ”¾ç½®çš„ä½ç½®å½±å“

æ•ˆæœï¼šä»»åŠ¡çš„DDLè¾¾æˆç‡å¾ˆé«˜ï¼Œæ²¡æœ‰æè®­ç»ƒçš„performance

ä¸åŒï¼šä¸æ¶‰åŠInter-GPU Sharingã€Batchä»ç„¶éœ€è¦å…¨å±€æŒ‡å®š

## \[OSDI 2022\] Synergy: Resource Sensitive DNN Scheduling in Multi-Tenant Clusters
ä½œè€…ï¼šJayashree Mohan, Amar Phanishayee, Janardhan Kulkarni, Vijay Chidambaram
å•ä½ï¼šMSRï¼ŒUT at Austinï¼ŒVMWare Research

Key Takeawaysï¼š
- é—®é¢˜ï¼šæœºå™¨å­¦ä¹ è®­ç»ƒä»»åŠ¡å¯¹CPUå’Œå†…å­˜æ˜¯æ•æ„Ÿçš„ï¼Œä½†æ˜¯ç›®å‰äº‘ä¸ŠæŒ‰ç…§ä¸€ä¸ªGPUé…æ¯”ä¸€å®šçš„CPUå’ŒMemoryå®ç°ã€‚
- è®¾è®¡äº†ä¸€å¥—Optimistic Profilingæœºåˆ¶æ¨æ–­ä»»åŠ¡å¯¹CPUå’Œå†…å­˜çš„æ•æ„Ÿç¨‹åº¦ã€‚
- è®¾è®¡äº†ä¸€å¥—workload-awareçš„åˆ†é…ç­–ç•¥ï¼Œå¾—åˆ°äº†æ€§èƒ½çš„æå‡ã€‚

æ–¹æ³•ï¼š
- Optimistic Profilingï¼šåˆ©ç”¨Throughputå’Œmemory allocationåˆ†é…ä¹‹é—´çš„å¯é¢„æµ‹æ€§ï¼Œåˆ©ç”¨å†…å­˜åˆ†é…çš„è¡Œä¸ºé¢„æµ‹CPUçš„ä½¿ç”¨æ•°é‡ã€‚
- Workload-awareåˆ†é…ï¼šå°†æ‰§è¡Œè¿‡ç¨‹çš„workloadéœ€æ±‚è½¬æ¢ä¸ºä¸€ä¸ªdemand vectorï¼Œæ±‚è§£çº¿æ€§æœ€ä¼˜ã€‚

æ•ˆæœï¼šæé«˜äº†ç¨‹åºçš„æ‰§è¡Œæ—¶é—´ï¼ˆ1.5x-2xï¼‰ã€‚

## \[Arxiv 2302.11358\]Faabric: Fine-Grained Distribution of Scientific Workloads in the Cloud
ä½œè€…ï¼šSimon Shillaker, Carlos Segarra, Eleftheria Mappoura, Mayeul Fournial, Lluis Vilanova, Peter Pietzuch
å•ä½ï¼šImperial College London

Key takeaways:
- ç§‘å­¦è®¡ç®—åœ¨ä¸“ç”¨çš„VMæ± å­é‡Œé¢çš„åˆ†é…ï¼Œå­˜åœ¨ä¸¥é‡çš„èµ„æºç¢ç‰‡é—®é¢˜ã€‚æ— æ³•åˆ©ç”¨æœªä½¿ç”¨çš„èµ„æºã€‚
- ç°æœ‰çš„Serverlessç¼–ç¨‹èŒƒå¼å¹¶ä¸æ”¯æŒå‡½æ•°é—´é€šä¿¡ï¼Œæå‡ºäº†Faabricï¼Œä½¿ç”¨çº¿ç¨‹å’Œè¿›ç¨‹ä½œä¸ºæŠ½è±¡çš„å•ä½ã€‚

é—®é¢˜ï¼šServerlessåœºæ™¯ä¸‹ä½¿ç”¨çº¿ç¨‹è¿›ç¨‹æ˜¯å¦æœ‰äº›å¥‡æ€ªï¼Ÿ

## \[IEEE Micro\] Failure Tolerant Training with Persistent Memory Disaggregation over CXL
ä½œè€…ï¼šMiryeong Kwon, Junhyeok Jang, Hanjin Choi, Sangwon Lee, Myoungsoo Jung
å•ä½ï¼šKAIST

Key takeaways:
- æå‡ºäº†åˆ©ç”¨CXLå®ç°ä½¿ç”¨Disaggreated MemoryåŒæ—¶è¾¾åˆ°ä½å¼€é”€Fault Toleranceï¼Œåº”ç”¨äºè¶…å¤§æ¨¡å‹çš„è®­ç»ƒã€‚
å…·ä½“è®¾è®¡ï¼š
(1) å°†æŒä¹…å†…å­˜ï¼ˆPMEMï¼‰å’ŒGPUæ•´åˆåˆ°ç¼“å­˜ä¸€è‡´çš„åŸŸï¼ˆType-2 CXLï¼‰
(2) åˆ†æäº†æ¨èç³»ç»Ÿï¼ˆRecommendation Systemï¼‰çš„ç‰¹ç‚¹å¹¶ä¸”å°†checkpointä»å…³é”®è·¯å¾„ä¸Šåˆ†ç¦»ã€‚å…·ä½“è€Œè¨€æ˜¯ï¼ŒBatch-aware Checkpointï¼Œåœ¨CXL-GPUã€CXL-MEMä¸ŠåŒæ—¶è¿›è¡ŒMLPçš„æ“ä½œ
(3) ç»™å‡ºäº†ä¸€ç§checkpointçš„æŠ€æœ¯ï¼Œå¯ä»¥relaxåœ¨batchä¹‹é—´æ›´æ–°å‚æ•°å’ŒåµŒå…¥å‘é‡
å¥‡æ€ªçš„è§‚å¯Ÿä¸æŒ‘æˆ˜ï¼š
- è§‚å¯Ÿ1ï¼šå·¥ä¸šä½¿ç”¨çš„RMï¼ˆæ¨èç³»ç»Ÿï¼‰ä¼šå ç”¨Tçº§åˆ«ç”šè‡³Pçº§åˆ«çš„å†…å­˜ï¼ˆå¼•ç”¨äº†Facebookçš„æ–‡ç« ï¼Œä½†æ˜¯åŸæ–‡é‡Œæ²¡æœ‰æåˆ°Pçº§åˆ«çš„å†…å­˜ï¼‰
- è§‚å¯Ÿ/æŒ‘æˆ˜2ï¼šæ¨èç³»ç»Ÿæ¨¡å‹éœ€è¦å®¹é”™ï¼ˆç²¾åº¦ä¸ä¸‹é™ï¼‰ï¼Œå› ä¸ºå…¶è®­ç»ƒæ—¶é—´é•¿ï¼Œé”™è¯¯å¼€é”€å¤§ã€‚åŒæ—¶snapshotçš„æ—¶å€™ä¸èƒ½æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚
æ•ˆæœï¼šä¸å…¶ä»–PMEMå·¥ä½œç›¸æ¯”ï¼Œè®­ç»ƒä¸Šæé«˜5.2xé€Ÿåº¦ï¼ŒèŠ‚çº¦76%èƒ½è€—ã€‚ï¼ˆWorkloadçš„å±æ€§å…¶å®æ²¡æœ‰åˆ©ç”¨å¥½ï¼‰

## \[ISCA 2022\] Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models
Tagï¼šNeoã€NeoEX
ä½œè€…ï¼šDheevatsa Mudigere, Yuchen Hao, Jianyu Huang, Zhihao Jia, Andrew Tulloch, Srinivas Sridharan, Xing Liu, Mustafa Ozdal, Jade Nie, Jongsoo Park, Liang Luo, Jie Amy Yang, Leon Gao, Dmytro Ivchenko, Aarti Basant, Yuxi Hu, Jiyan Yang, Ehsan K. Ardestani, Xiaodong Wang, Rakesh Komuravelli, Ching-Hsiang Chu, Serhat Yilmaz, Huayu Li, Jiyuan Qian, Zhuobo Feng, Yinbin Ma, Junjie Yang, Ellie Wen, Hong Li, Lin Yang, Chonglin Sun, Whitney Zhao, Dimitry Melts, Krishna Dhulipala, KR Kishore, Tyler Graf, Assaf Eisenman, Kiran Kumar Matam, Adi Gangidi, Guoqiang Jerry Chen, Manoj Krishnan, Avinash Nayak, Krishnakumar Nair, Bharath Muthiah, Mahmoud khorashadi, Pallab Bhattacharya, Petr Lapukhov, Maxim Naumov, Ajit Mathews, Lin Qiao, Mikhail Smelyanskiy, Bill Jia, Vijay Rao
å•ä½ï¼šMetaã€CMU

é—®é¢˜ï¼šæ¨èç³»ç»Ÿå­˜åœ¨å¤§é‡Data-intensiveçš„embedding operatorsï¼Œè¿™äº›operatorså¯¹ç®—åŠ›çš„å ç”¨ç›¸å¯¹æ¯”è¾ƒå°‘ã€‚ç›®å‰çš„è½¯ä»¶å’Œç¡¬ä»¶ä¸èƒ½å¾ˆå¥½çš„é€‚é…è¿™ä¸€è¶‹åŠ¿ã€‚ï¼ˆå°±æ˜¯æ¨¡å‹éå¸¸åƒæ•°æ®ï¼‰
- è½¯ä»¶é—®é¢˜ï¼šç°åœ¨æ·±åº¦å­¦ä¹ çš„å¹¶è¡Œå¯ä»¥åˆ†ä¸ºæ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œå’Œpipelineã€‚ä½†æ˜¯è¿™äº›å¹¶è¡Œä¸»è¦ä¼˜åŒ–compute-intensiveï¼Œè€Œä¸æ˜¯data-intensiveã€‚
- ç¡¬ä»¶é—®é¢˜ï¼šç¡¬ä»¶ä¸»è¦åŠ é€ŸèŠ‚ç‚¹é—´çš„ä¸­å¿ƒåŒ–æ•°æ®åŒæ­¥ï¼ˆä¾‹å¦‚å‚æ•°æœåŠ¡ï¼‰å’ŒAllReduceï¼ˆNCCLï¼‰ï¼Œä½†æ˜¯DLRMå®é™…ä¸Šå­˜åœ¨æ›´å¤æ‚çš„èŠ‚ç‚¹é—´é€šä¿¡èŒƒå¼ã€‚

æ–¹æ³•ï¼š
- æå‡º4ä¸ªç»´åº¦çš„å¹¶è¡Œï¼šTable-wiseã€Row-wiseã€Column-wiseå’Œdataçš„parallelism
- é«˜æ€§èƒ½çš„Embeddingè®¡ç®—ï¼š(1)æ··åˆçš„CUDAå†…æ ¸èåˆæŠ€æœ¯ï¼ˆèåˆEmbeddingç®—å­å’ŒEmbeddingè®¡ç®—ä»¥åŠä»–ä»¬çš„æ›´æ–°ï¼‰(2)è½¯ä»¶ç®¡ç†çš„ç¼“å­˜æœºåˆ¶å’Œå†…å­˜å‹ç¼©æœºåˆ¶ã€‚
- ç¡¬ä»¶å¹³å°è®¾è®¡ï¼šä¸“ç”¨RDMAèŠ‚ç‚¹ï¼Œä¸»è¦æ˜¯è€ƒè™‘ç½‘ç»œé€šä¿¡

ç»“æœï¼šåœ¨128å¼ A100çš„GPU + 16ä¸ªç½‘ç»œèŠ‚ç‚¹çš„ç»„åˆæé«˜äº†40å€è®­ç»ƒé€Ÿåº¦ã€‚

## \[ACM Measure 23\] DaeMon: Architectural Support for Efficient Data Movement in Fully Disaggregated Systems
Tagï¼šDaeMon
ä½œè€…ï¼š Christina Giannoula, Kailong Huang, Jonathan Tang, Nectarios Koziris, Georgios Goumas, Zeshan Chishti, Nandita Vijaykumar
å•ä½ï¼šUniversity of Toronto

Key Takeaways:
- åœ¨Disaggreated Systemä¸Šï¼Œè¿œç¨‹å†…å­˜çš„æ¬è¿å¼€é”€éå¸¸å¤§ã€‚
- è®¾è®¡äº†Daemonåˆ©ç”¨ä¸“ç”¨å¼•æ“å®ç°äº†å¯¹ä¸Šå±‚è½¯ä»¶é€æ˜çš„è®¡ç®—ï¼Œå®ç°äº†è‡ªé€‚åº”çš„ç²’åº¦é…ç½®ï¼ˆåŸºäºå¸¦å®½åˆ‡åˆ†ã€é“¾è·¯å‹ç¼©å’Œæ•°æ®æ¬è¿è§£è€¦ï¼‰
- æ•ˆæœï¼šä¸é¡µç²’åº¦çš„æ¬è¿ç›¸æ¯”è·å¾—äº†2.39xå’Œ3.06xçš„æ•°æ®ç§»åŠ¨åŠ é€Ÿã€‚

å…³é”®æŠ€æœ¯ï¼š
- æŠŠæ•°æ®è¿ç§»offloadç»™ä¸“ç”¨ç¡¬ä»¶å¼•æ“å¤„ç†ã€‚
- ä¼˜å…ˆè€ƒè™‘ç¼“å­˜è¡Œçº§åˆ«çš„æ•°æ®ç§»åŠ¨ï¼Œåˆ©ç”¨ç¡¬ä»¶é“¾æ¥å‹ç¼©ï¼ˆæŠŠå¤šä¸ªç¼“å­˜è¡Œçš„è®¿é—®å‹ç¼©æˆä¸€ä¸ªpageï¼‰æ¥å‡å°‘ç½‘ç»œå¸¦å®½æ¶ˆè€—å¹¶å‡è½»æ’é˜Ÿå»¶è¿Ÿã€‚



